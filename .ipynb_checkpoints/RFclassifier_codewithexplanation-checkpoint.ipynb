{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Predicting the Success of a Kickstarter Campaign: Sharon Agai </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/kemical/kickstarter-projects#ks-projects-201801.csv <br>\n",
    "I used the second data source provided, ks-projects-2018-01. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial thoughts\n",
    "- Classification vs. clustering - we have a large training dataset, so a supervised learning-based approached such as classification should work well\n",
    "- Classification algorithm candidates: logistic regression, K-NN, SVM, Naive Bayes, Decision Tree, Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### Preprocessing - data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ks-projects-201801.csv\")\n",
    "data.columns = data.columns.str.replace(' ', '_')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique project states: \", data['state'].unique())\n",
    "print(\"Unique main categories: \", data['main_category'].unique())\n",
    "print(\"Unique categories: \", data['category'].unique())\n",
    "print(\"Unique countries: \", data['country'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6 possible project states - successful, failed, canceled, live, undefined, and suspended. Since we are trying to predict success and failure, I will extract those only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fixing a small entry error\n",
    "data.country = data.country.replace(to_replace='N,0\"', value='NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successdata = data[data.state == 'successful']\n",
    "faildata = data[data.state == 'failed']\n",
    "alldata = pd.concat([successdata, faildata])\n",
    "print(alldata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change launched and deadline to datetime format and create a new column called duration\n",
    "\n",
    "alldata.launched = pd.to_datetime(alldata.launched, format='%Y-%m-%d %H:%M:%S')\n",
    "alldata.deadline = pd.to_datetime(alldata.deadline, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "alldata['duration']=alldata['deadline']-alldata['launched']\n",
    "alldata.duration = alldata.duration.dt.days\n",
    "alldata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with many NaNs and duplicate rows next. <br>\n",
    "Also, looking at the data reveals that some of this information can be condensed. For example, above we combined launched and deadline to create duration. Also, usd_pledged_real is made up of pledged and currency and usd_goal_real is made up of goal and currency. Additionally, ID and name don't give us much information about the success of the project. Lastly, category and main_category are quite similar, but the latter offers a more general perspective, which leads me to believe using it would result in less noise and help us avoid overfitting (via dimensionality reduction). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata.drop_duplicates()\n",
    "alldata.isnull().sum()\n",
    "    \n",
    "alldata.drop(columns=['ID', 'category', 'currency', 'deadline', 'goal', 'launched', 'name', 'pledged', 'usd_pledged'], \n",
    "              inplace=True)\n",
    "\n",
    "alldata.isnull().sum()\n",
    "print(alldata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the continuous variables (backers, usd_pledged_real, usd_goal_real, and duration) against state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2,ncols=2,figsize=(18,6))\n",
    "\n",
    "sns.stripplot(x='backers', y='state', data=alldata, jitter=True, linewidth=0.8, ax=ax[0,0])\n",
    "ax[0,0].set_title('Number of backers by campaign state')\n",
    "sns.stripplot(x='duration', y='state', data=alldata, jitter=True, linewidth=0.8, ax=ax[0,1])\n",
    "ax[0,1].set_title('Campaign duration by campaign state')\n",
    "sns.stripplot(x='usd_goal_real', y='state', data=alldata, jitter=True, linewidth=0.8, ax=ax[1,0])\n",
    "ax[1,0].set_title('Campaign pledge goal by campaign state')\n",
    "sns.stripplot(x='usd_pledged_real', y='state', data=alldata, jitter=True, linewidth=0.8, ax=ax[1,1])\n",
    "ax[1,1].set_title('Amount pledged to campaign by campaign state')\n",
    "\n",
    "fig.subplots_adjust(hspace=1.2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsuccessful campaigns have a consistently low number of backers and total amount pledged (unlike successful campaigns, which vary widely in this respect). <br>\n",
    "Conversely, successful campaigns tend to have consistently low campaign pledge goals (unlike unsuccessful campaigns, which vary widely in this respect). <br>\n",
    "Lastly, campaign duration varies widely for both successful and unsuccessful campaigns. This trend surprised me the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_vars = pd.concat([alldata.backers, alldata.usd_pledged_real, alldata.usd_goal_real,\n",
    "                      alldata.duration, alldata.state], axis=1)\n",
    "g = sns.pairplot(cont_vars, hue='state', diag_kind='kde')\n",
    "g.set(xlim=(0,300000), ylim=(0,300000))\n",
    "g.fig.suptitle('Pairplot: All continuous variables against each other and state', size=20)\n",
    "g.fig.subplots_adjust(top=.9)\n",
    "for ax in g.axes.flat: \n",
    "    plt.setp(ax.get_xticklabels(), rotation=-50)\n",
    "g.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u>Pair-wise comparisons</u></b><br> I will focus on analzing a few interesting pairwise comparisons:<br>\n",
    "-  <b>usd_goal_real vs. backers and backers vs. usd_goal_real:</b> successful campaigns have more backers, regardless of the campaign's pledge goal. <br> \n",
    "-  <b>backers vs. usd_pledged_real:</b> the number of backers and how much money was pledged to the campaign are not correlated. In other words, a campaign with few people donating large amounts and a campaign with many people donating small amounts can both be successful. <br> \n",
    "-  <b>usd_goal_real vs. usd_pledged_real and usd_goal_real vs. usd_pledged_real:</b> in successful campaigns, the campaign goal is met. In unsuccessful campaigns, it is not met. The perfect split with slope=1 between successful and failed campaigns tells us how \"success\" is defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u>Diagonals</u></b><br> The KDE plots confirm the trends we noticed in the previous graphs above.<br> \n",
    "-  <b>backers:</b> As seen above, unsuccessful campaigns are likely to have few backers while successful campaigns are likely to have many backers.<br> \n",
    "- <b>usd_pledged_real:</b> Successful campaigns are likely to have a wide range of pledged amounts, while unsuccessful campaigns are likely to have very little money pledged to them.<br> \n",
    "- <b>usd_goal_real:</b> Successful campaigns are likely to have low funding goals, whereas unsuccessful campaigns are likely to have a range of funding goal.<br> \n",
    "-  <b>duration:</b> Like above, there isn't really a discernable pattern when it comes to campaign duration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the categorical variables (country and main_category) against state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20,6))\n",
    "\n",
    "sns.countplot(y=\"main_category\", hue=\"state\", data=alldata, ax=ax[0])\n",
    "ax[0].set_title('Campaign state by main_category')\n",
    "\n",
    "sns.countplot(y=\"country\", hue=\"state\", data=alldata, ax=ax[1])\n",
    "ax[1].set_title('Campaign state by country')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Are any categories or countries particularly successful or unsuccessful? </b><br> \n",
    "-  The number of successful and unsuccessful campaigns varies most in <i>food</i>, <i>fashion</i>, <i>film and video</i>, <i>publishing</i>, and <i>technology</i>. There are significantly more failed campaigns than successful campaigns in these categories. The only categories with more successful campaigns than failed ones are <i>music</i>, <i>comics</i>, <i>theater</i>, and <i>dance</i>. I would guess this has to do with Kickstarter's audience and the resulting culture around Kickstarter.<br>\n",
    "-  The number of successful and failed campaigns in each country seems to be fairly proportional. However, it's interesting to note that Italy, Germany, the Netherlands, and Spain appear to have particularly high numbers of unsuccessful campaigns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the continuous variables with the categorical variables and state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "ax = sns.barplot(x='main_category', y='backers', hue='state', data=alldata)\n",
    "ax.set_title('Campaign state by main_category and number of backers', size=12)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=-50)\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1,0.5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "ax = sns.barplot(x='main_category', y='duration', hue='state', data=alldata)\n",
    "ax.set_title('Campaign state by main_category and campaign duration', size=12)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=-50)\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1,0.5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "ax = sns.barplot(x='main_category', y='usd_goal_real', hue='state', data=alldata)\n",
    "ax.set_title('Campaign state by main_category and funding goal', size=12)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=-50)\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1,0.5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "ax = sns.barplot(x='main_category', y='usd_pledged_real', hue='state', data=alldata)\n",
    "ax.set_title('Campaign state by main_category and actual amount pledged', size=12)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=-50)\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1,0.5))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "ax = sns.barplot(x='country', y='backers', hue='state', data=alldata)\n",
    "ax.set_title('Campaign state by country and number of backers', size=12)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=-50)\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1,0.5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "ax = sns.barplot(x='country', y='duration', hue='state', data=alldata)\n",
    "ax.set_title('Campaign state by country and campaign duration', size=12)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=-50)\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1,0.5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "ax = sns.barplot(x='country', y='usd_goal_real', hue='state', data=alldata)\n",
    "ax.set_title('Campaign state by country and funding goal', size=12)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=-50)\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1,0.5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "ax = sns.barplot(x='country', y='usd_pledged_real', hue='state', data=alldata)\n",
    "ax.set_title('Campaign state by country and actual amount pledged', size=12)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=-50)\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1,0.5))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of these two visualizations is to understand the way category and country play into campaign success for each continuous variable, separately. The trends in <i>backers</i>, <i>usd_goal_real</i>, <i>usd_pledged_real</i> that we saw above. From the <i>duration</i> graph, we see that unsuccessful campaigns tend to have slightly longer durations across all categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model\n",
    "#### ML Model - Algorithm choice\n",
    "I will proceed with Random Forest classification. Its accuracy and power are hard to beat, and it has a fairly simple implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML Model - Creating and implementing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a function to make and fit a classifier, predict y_values, and build some accuracy metrics \n",
    "\n",
    "def RandomForest(randomState, X_train, X_test, y_train, y_test):\n",
    "    global classifier\n",
    "    global cm\n",
    "    # Creation and fit\n",
    "    classifier = RandomForestClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Prediction\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Important metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables for categories - one-hot encoding\n",
    "alldata_enc = pd.get_dummies(alldata, columns=['state', 'main_category', 'country'])\n",
    "alldata_enc.head()\n",
    "\n",
    "# Extracting column names for tree visualization later\n",
    "cols = list(alldata_enc.columns)\n",
    "cols.remove('state_failed')\n",
    "cols.remove('state_successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a training set and a test set \n",
    "X = alldata_enc.drop(['state_successful', 'state_failed'], axis='columns').values\n",
    "y = alldata_enc.state_successful.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize sklearn's built-in scorer\n",
    "scorer = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This is where the magic happens!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest(0, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10-fold cross-validation of results\n",
    "crossvalidation = np.mean(cross_val_score(classifier, X, y, cv=10))\n",
    "print(np.mean(crossvalidation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "#### Conclusion - interpreting and visualizing the results of our random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import itertools\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing one decision tree\n",
    "estimator = classifier.estimators_[5]\n",
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render('tree')\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                                feature_names=cols,\n",
    "                                class_names=['state_successful', 'state_failed'],\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the output of the tree diagram: <br>\n",
    "-  According to GINI, an impurity metric intended to minimize misclassification in binary classifiers, we start (in this tree) with <i>backers</i>. This means the GINI coefficient found <i>backers</i> to be a good feature by which to split the data initially. I would guess that this means <i>backers</i> is an important feature in determining the success or failure of a campaign. We will look at feature importances later to confirm this. <br>\n",
    "-  Each node tells us how data in the next node should be split (GINI), the number of samples that remain unclassified, guesses for classification of those samples, and the classification of the samples at that node.\n",
    "-  The decision tree stops when a bin has less than 20 samples or GINI=0.0000 (i.e. the bin contains only one class, there are no impurities). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix \n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix(cm, target_names=['Successful', 'Failed'], title='Confusion matrix', cmap=None, normalize=True)\n",
    "print('Confusion matrix (values): ')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classifier correctly predicts successful campaigns 99.4% of the time, and correctly predicts unsuccessful campaigns 99.7% on this run. Cross-validation (above) confirms that this result represents the classifier's performance well. <br>\n",
    "Given the context of the problem, predicting success and getting failure (i.e. a false positive) is harmful, whereas the opposite (predicting failure and getting success, a false negative) isn't. Therefore, precision is the best metric to measure the performance of our model. <br>\n",
    "Precision = true positives/total predicted positives = 39204/39290 = 0.9987, or 99.87% precision. <br>\n",
    "This is good, I am happy with the performance of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting feature importances\n",
    "feature_importances = classifier.feature_importances_\n",
    "\n",
    "feature_importances_df = pd.DataFrame(feature_importances, \n",
    "                                   index= alldata_enc.drop(['state_successful', 'state_failed'], axis='columns').columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "keyfeatures_df = feature_importances_df[:4]\n",
    "keyfeaturenames = np.array(keyfeatures_df.index)\n",
    "print(keyfeatures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting feature importances\n",
    "y = classifier.feature_importances_[:4]\n",
    "cols=keyfeaturenames\n",
    "\n",
    "fig, ax = plt.subplots() \n",
    "\n",
    "width = 0.4 # the width of the bars \n",
    "ind = np.arange(len(y)) # the x locations for the groups\n",
    "\n",
    "ax.barh(ind, y, width, color='green')\n",
    "ax.set_yticks(ind+width/10)\n",
    "ax.set_yticklabels(cols, minor=False)\n",
    "plt.title('Feature Importance in Random Forest Classifier')\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.ylabel('feature') \n",
    "plt.figure(figsize=(5,5))\n",
    "fig.set_size_inches(6.5, 4.5, forward=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I extracted the most important features by using a built-in method that permutes each column of data and measures the resulting increase an error. Features with higher importance cause a greater increase in error (i.e. removing them does the most damage to the algorithm's success). The results of the key feature extraction align with what I would guess, for the most part. Based on the visualizations above, it makes sense that the most important features in predicting the success of a Kickstarter campaign are the amount of money pledged to it and the number of backers, and that funding goal is close behind. I was most surprised by duration's importance because no clear pattern was evident when visualizing the data earlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this dataset would perform well with a neural network. Although the Random Forest Classifier achieves very good results already, it would be interesting to compare its results with those of a neural network. I also think it would be interesting to investigate more thoroughly the launch and deadline dates of this dataset. Do campaigns perform significantly better/worse around a certain time of year? For example, how does the holiday season affect the success of Kickstarter campaigns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources \n",
    "\n",
    "https://github.com/mkucz95/kickstarter_data/blob/master/kickstarter_data.ipynb\n",
    "\n",
    "https://github.com/bodealamu/Prediction-of-success-in-a-kickstarter-campaign/blob/master/kickstarter%20project.ipynb\n",
    "\n",
    "https://github.com/gagejustins/Kickstarter/blob/master/kickstarter.ipynb\n",
    "\n",
    "https://www.kaggle.com/grfiv4/plot-a-confusion-matrix\n",
    "\n",
    "https://medium.com/@garg.mohit851/random-forest-visualization-3f76cdf6456f\n",
    "\n",
    "https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "https://stackoverflow.com/questions/19233771/sklearn-plot-confusion-matrix-with-labels/48018785\n",
    "\n",
    "https://towardsdatascience.com/running-random-forests-inspect-the-feature-importances-with-this-code-2b00dd72b92e\n",
    "\n",
    "https://www.udemy.com/machinelearning/learn/v4/content\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
