{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'name', 'category', 'main_category', 'currency', 'deadline',\n",
       "       'goal', 'launched', 'pledged', 'state', 'backers', 'country',\n",
       "       'usd_pledged', 'usd_pledged_real', 'usd_goal_real'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ks-projects-201801.csv\")\n",
    "data.columns = data.columns.str.replace(' ', '_')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID                                               name  \\\n",
      "5   1000014025                               Monarch Espresso Bar   \n",
      "6   1000023410  Support Solar Roasted Coffee & Green Energy!  ...   \n",
      "11   100005484                                   Lisa Lim New CD!   \n",
      "14  1000057089  Tombstone: Old West tabletop game and miniatur...   \n",
      "18  1000070642                Mike Corey's Darkness & Light Album   \n",
      "\n",
      "          category main_category currency    deadline     goal  \\\n",
      "5      Restaurants          Food      USD  2016-04-01  50000.0   \n",
      "6             Food          Food      USD  2014-12-21   1000.0   \n",
      "11      Indie Rock         Music      USD  2013-04-08  12500.0   \n",
      "14  Tabletop Games         Games      GBP  2017-05-03   5000.0   \n",
      "18           Music         Music      USD  2012-08-17    250.0   \n",
      "\n",
      "               launched  pledged       state  backers country  usd_pledged  \\\n",
      "5   2016-02-26 13:38:27  52375.0  successful      224      US     52375.00   \n",
      "6   2014-12-01 18:30:44   1205.0  successful       16      US      1205.00   \n",
      "11  2013-03-09 06:42:58  12700.0  successful      100      US     12700.00   \n",
      "14  2017-04-05 19:44:18  94175.0  successful      761      GB     57763.78   \n",
      "18  2012-08-02 14:11:32    250.0  successful        7      US       250.00   \n",
      "\n",
      "    usd_pledged_real  usd_goal_real  \n",
      "5           52375.00       50000.00  \n",
      "6            1205.00        1000.00  \n",
      "11          12700.00       12500.00  \n",
      "14         121857.33        6469.73  \n",
      "18            250.00         250.00  \n"
     ]
    }
   ],
   "source": [
    "# Fixing a small entry error\n",
    "data.country = data.country.replace(to_replace='N,0\"', value='NO')\n",
    "\n",
    "successdata = data[data.state == 'successful']\n",
    "faildata = data[data.state == 'failed']\n",
    "alldata = pd.concat([successdata, faildata])\n",
    "print(alldata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_category       0\n",
       "state               0\n",
       "backers             0\n",
       "country             0\n",
       "usd_pledged_real    0\n",
       "usd_goal_real       0\n",
       "duration            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change launched and deadline to datetime format and create a new column called duration\n",
    "\n",
    "alldata.launched = pd.to_datetime(alldata.launched, format='%Y-%m-%d %H:%M:%S')\n",
    "alldata.deadline = pd.to_datetime(alldata.deadline, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "alldata['duration']=alldata['deadline']-alldata['launched']\n",
    "alldata.duration = alldata.duration.dt.days\n",
    "\n",
    "alldata.drop_duplicates()\n",
    "alldata.isnull().sum()\n",
    "    \n",
    "alldata.drop(columns=['ID', 'category', 'currency', 'deadline', 'goal', 'launched', 'name', 'pledged', 'usd_pledged'], \n",
    "              inplace=True)\n",
    "\n",
    "alldata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a function to make and fit a classifier, predict y_values, and build some accuracy metrics \n",
    "\n",
    "def RandomForest(randomState, X_train, X_test, y_train, y_test):\n",
    "    # Creation and fit\n",
    "    global classifier\n",
    "    #global cm\n",
    "    #global y_pred\n",
    "    classifier = RandomForestClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Prediction\n",
    "    #y_pred = classifier.predict(X_test)\n",
    "    \n",
    "#     # Important metrics\n",
    "#     cm = confusion_matrix(y_test, y_pred)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating dummy variables for categories - one-hot encoding\n",
    "alldata_enc = pd.get_dummies(alldata, columns=['state', 'main_category', 'country'])\n",
    "alldata_enc.head()\n",
    "\n",
    "# Extracting column names for tree visualization later\n",
    "cols = list(alldata_enc.columns)\n",
    "cols.remove('state_failed')\n",
    "cols.remove('state_successful')\n",
    "\n",
    "#Create a training set and a test set \n",
    "X = alldata_enc.drop(['state_successful', 'state_failed'], axis='columns').values\n",
    "y = alldata_enc.state_successful.values\n",
    "X_t, X_test, y_t, y_test = train_test_split(X, y, test_size = 0.18)\n",
    "\n",
    "# Adding a validation set \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_t, y_t, test_size = 0.22)\n",
    "\n",
    "# Initialize sklearn's built-in scorer\n",
    "scorer = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does our new train/val/test split yield?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35434   232]\n",
      " [  110 24059]]\n",
      "[[35553   218]\n",
      " [  117 23814]]\n"
     ]
    }
   ],
   "source": [
    "RandomForest(0, X_train, X_val, y_train, y_val)\n",
    "val_pred = classifier.predict(X_val)\n",
    "val_cm = confusion_matrix(y_val, val_pred)\n",
    "print(val_cm)\n",
    "\n",
    "test_pred = classifier.predict(X_test)\n",
    "test_cm = confusion_matrix(y_test, test_pred)\n",
    "print(test_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set precision:  99.94640792034525 %\n",
      "Test set precision:  99.67199327165686 %\n"
     ]
    }
   ],
   "source": [
    "#true positives/total predicted positives\n",
    "\n",
    "val_precision = (35434/(35343+110)*100)\n",
    "test_precision = (35553/(35553+117)*100)\n",
    "print('Validation set precision: ', val_precision,'%')\n",
    "print('Test set precision: ', test_precision,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = np.arange(5,len(X_train),10000)\n",
    "\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "                                                   classifier, X, y, train_sizes = train_sizes, cv = 3,\n",
    "                                                   scoring = 'accuracy')\n",
    "\n",
    "train_scores_mean = train_scores.mean(axis = 1)\n",
    "validation_scores_mean = validation_scores.mean(axis = 1)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, label = 'Train set')\n",
    "plt.plot(train_sizes, validation_scores_mean, label = 'Validation set')\n",
    "\n",
    "plt.ylabel('Accuracy', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curve for random forest classifier', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.ylim(0.4,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Calculate roc auc\n",
    "rf_probs = classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(2):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, rf_probs)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "print(roc_auc_score(y_test, rf_probs))\n",
    "plt.figure()\n",
    "plt.plot(fpr[1], tpr[1])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.show()\n",
    "\n",
    "print(auc(fpr[1], tpr[1]))\n",
    "\n",
    "# measure of separability, close to 1 = good at predicting correctly, x is false positive and y is true positive \n",
    "# https://www.kaggle.com/learn-forum/53782"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
